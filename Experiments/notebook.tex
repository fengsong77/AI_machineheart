
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{tf\_orginal\_CapsNet}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{}以下代码修改自naturomics的GitHub实现，包含三层CapsNet和后面的重构网络}
        \PY{c+c1}{\PYZsh{}改网络参数比较多，我们后面会只训练测试三层CapsNet。}
        
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k+kn}{as} \PY{n+nn}{tf}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k+kn}{import} \PY{n}{tqdm}
        
        \PY{n}{epsilon} \PY{o}{=} \PY{l+m+mf}{1e\PYZhy{}9}
        \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{8}
        \PY{n}{epoch} \PY{o}{=} \PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{}margin loss 中调节上margin和下margind的权重}
        \PY{n}{lambda\PYZus{}val} \PY{o}{=} \PY{l+m+mf}{0.5}
        \PY{c+c1}{\PYZsh{}上margin与下margin的参数值}
        \PY{n}{m\PYZus{}plus} \PY{o}{=} \PY{l+m+mf}{0.9}
        \PY{n}{m\PYZus{}minus} \PY{o}{=} \PY{l+m+mf}{0.1}
        
        \PY{c+c1}{\PYZsh{} 路由更新c\PYZus{}ij所经过的迭代次数}
        \PY{n}{iter\PYZus{}routing} \PY{o}{=} \PY{l+m+mi}{3}
        
        \PY{c+c1}{\PYZsh{} Tensorboard 保存位置}
        \PY{n}{logdir} \PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{logdir}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} 数据集路径}
        \PY{n}{dataset\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/MNIST}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{is\PYZus{}training}\PY{o}{=} \PY{n+nb+bp}{True}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} 定义加载mnist的函数}
        \PY{k}{def} \PY{n+nf}{load\PYZus{}mnist}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{n}{is\PYZus{}training}\PY{p}{)}\PY{p}{:}
        
            \PY{c+c1}{\PYZsh{}trX将加载储存所有60000张灰度图}
            \PY{n}{fd} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZhy{}images\PYZhy{}idx3\PYZhy{}ubyte}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{loaded} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{fromfile}\PY{p}{(}\PY{n+nb}{file}\PY{o}{=}\PY{n}{fd}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
            \PY{n}{trX} \PY{o}{=} \PY{n}{loaded}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{60000}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{)}
        
            \PY{n}{fd} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZhy{}labels\PYZhy{}idx1\PYZhy{}ubyte}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{loaded} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{fromfile}\PY{p}{(}\PY{n+nb}{file}\PY{o}{=}\PY{n}{fd}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
            \PY{n}{trY} \PY{o}{=} \PY{n}{loaded}\PY{p}{[}\PY{l+m+mi}{8}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{60000}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{}teX将储存所有一万张测试用的图片}
            \PY{n}{fd} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t10k\PYZhy{}images\PYZhy{}idx3\PYZhy{}ubyte}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{loaded} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{fromfile}\PY{p}{(}\PY{n+nb}{file}\PY{o}{=}\PY{n}{fd}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
            \PY{n}{teX} \PY{o}{=} \PY{n}{loaded}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{)}
        
            \PY{n}{fd} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t10k\PYZhy{}labels\PYZhy{}idx1\PYZhy{}ubyte}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{loaded} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{fromfile}\PY{p}{(}\PY{n+nb}{file}\PY{o}{=}\PY{n}{fd}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
            \PY{n}{teY} \PY{o}{=} \PY{n}{loaded}\PY{p}{[}\PY{l+m+mi}{8}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} 将所有训练图片表示为一个4维张量 [60000, 28, 28, 1]，其中每个像素值缩放到0和1之间}
            \PY{n}{trX} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{convert\PYZus{}to\PYZus{}tensor}\PY{p}{(}\PY{n}{trX} \PY{o}{/} \PY{l+m+mf}{255.}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} one hot编码为 [num\PYZus{}samples, 10]}
            \PY{n}{trY} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{one\PYZus{}hot}\PY{p}{(}\PY{n}{trY}\PY{p}{,} \PY{n}{depth}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
            \PY{n}{teY} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{one\PYZus{}hot}\PY{p}{(}\PY{n}{teY}\PY{p}{,} \PY{n}{depth}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} 训练和测试时返回不同的数据}
            \PY{k}{if} \PY{n}{is\PYZus{}training}\PY{p}{:}
                \PY{k}{return} \PY{n}{trX}\PY{p}{,} \PY{n}{trY}
            \PY{k}{else}\PY{p}{:}
                \PY{k}{return} \PY{n}{teX} \PY{o}{/} \PY{l+m+mf}{255.}\PY{p}{,} \PY{n}{teY}
        
        \PY{k}{def} \PY{n+nf}{get\PYZus{}batch\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{n}{trX}\PY{p}{,} \PY{n}{trY} \PY{o}{=} \PY{n}{load\PYZus{}mnist}\PY{p}{(}\PY{n}{dataset\PYZus{}path}\PY{p}{,} \PY{n+nb+bp}{True}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} 每次产生一个切片}
            \PY{n}{data\PYZus{}queues} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{slice\PYZus{}input\PYZus{}producer}\PY{p}{(}\PY{p}{[}\PY{n}{trX}\PY{p}{,} \PY{n}{trY}\PY{p}{]}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} 对队列中的样本进行乱序处理}
            \PY{n}{X}\PY{p}{,} \PY{n}{Y} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{shuffle\PYZus{}batch}\PY{p}{(}\PY{n}{data\PYZus{}queues}\PY{p}{,}
                                          \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch\PYZus{}size}\PY{p}{,}
                                          \PY{n}{capacity}\PY{o}{=}\PY{n}{batch\PYZus{}size} \PY{o}{*} \PY{l+m+mi}{64}\PY{p}{,}
                                          \PY{n}{min\PYZus{}after\PYZus{}dequeue}\PY{o}{=}\PY{n}{batch\PYZus{}size} \PY{o}{*} \PY{l+m+mi}{32}\PY{p}{,}
                                          \PY{n}{allow\PYZus{}smaller\PYZus{}final\PYZus{}batch}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}
            \PY{k}{return} \PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} 通过定义类和对象的方式定义Capssule层级}
        \PY{k}{class} \PY{n+nc}{CapsLayer}\PY{p}{(}\PY{n+nb}{object}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{} Capsule layer 类别参数有：}
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        input: 一个4维张量}
        \PY{l+s+sd}{        num\PYZus{}outputs: 当前层的Capsule单元数量}
        \PY{l+s+sd}{        vec\PYZus{}len: 一个Capsule输出向量的长度}
        \PY{l+s+sd}{        layer\PYZus{}type: 选择\PYZsq{}FC\PYZsq{} 或 \PYZdq{}CONV\PYZdq{}, 以确定是用全连接层还是卷积层}
        \PY{l+s+sd}{        with\PYZus{}routing: 当前Capsule是否从较低层级中Routing而得出输出向量}
        
        \PY{l+s+sd}{    Returns:}
        \PY{l+s+sd}{        一个四维张量}
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}outputs}\PY{p}{,} \PY{n}{vec\PYZus{}len}\PY{p}{,} \PY{n}{with\PYZus{}routing}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{layer\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FC}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{num\PYZus{}outputs} \PY{o}{=} \PY{n}{num\PYZus{}outputs}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{vec\PYZus{}len} \PY{o}{=} \PY{n}{vec\PYZus{}len}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{with\PYZus{}routing} \PY{o}{=} \PY{n}{with\PYZus{}routing}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}type} \PY{o}{=} \PY{n}{layer\PYZus{}type}
        
            \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}call\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n+nb}{input}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{        当“Layer\PYZus{}type”选择的是“CONV”，我们将使用 \PYZsq{}kernel\PYZus{}size\PYZsq{} 和 \PYZsq{}stride\PYZsq{}}
        \PY{l+s+sd}{        \PYZsq{}\PYZsq{}\PYZsq{}}
        
                \PY{c+c1}{\PYZsh{} 开始构建卷积层}
                \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}type} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CONV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{kernel\PYZus{}size} \PY{o}{=} \PY{n}{kernel\PYZus{}size}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{stride} \PY{o}{=} \PY{n}{stride}
        
                    \PY{c+c1}{\PYZsh{} PrimaryCaps层没有Routing过程}
                    \PY{k}{if} \PY{o+ow}{not} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{with\PYZus{}routing}\PY{p}{:}
                        \PY{c+c1}{\PYZsh{} 卷积层为 PrimaryCaps 层（CapsNet第二层）, 并将第一层卷积的输出张量作为输入。}
                        \PY{c+c1}{\PYZsh{} 输入张量的维度为： [batch\PYZus{}size, 20, 20, 256]}
                        \PY{k}{assert} \PY{n+nb}{input}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{]}
        
                        \PY{c+c1}{\PYZsh{} \PYZsh{} 从CapsNet输出向量的每一个分量开始执行卷积，每个分量上执行带32个卷积核的9×9标准卷积}
                        \PY{c+c1}{\PYZsh{} capsules = []}
                        \PY{c+c1}{\PYZsh{} for i in range(self.vec\PYZus{}len):}
                        \PY{c+c1}{\PYZsh{}     \PYZsh{} 所有Capsule的一个分量，其维度为: [batch\PYZus{}size, 6, 6, 32]，即6×6×1×32}
                        \PY{c+c1}{\PYZsh{}     with tf.variable\PYZus{}scope(\PYZsq{}ConvUnit\PYZus{}\PYZsq{} + str(i)):}
                        \PY{c+c1}{\PYZsh{}         caps\PYZus{}i = tf.contrib.layers.conv2d(input, self.num\PYZus{}outputs,}
                        \PY{c+c1}{\PYZsh{}                                           self.kernel\PYZus{}size, self.stride,}
                        \PY{c+c1}{\PYZsh{}                                           padding=\PYZdq{}VALID\PYZdq{})}
                        \PY{c+c1}{\PYZsh{}}
                        \PY{c+c1}{\PYZsh{}         \PYZsh{} 将一般卷积的结果张量拉平，并为添加到列表中}
                        \PY{c+c1}{\PYZsh{}         caps\PYZus{}i = tf.reshape(caps\PYZus{}i, shape=(batch\PYZus{}size, \PYZhy{}1, 1, 1))}
                        \PY{c+c1}{\PYZsh{}         capsules.append(caps\PYZus{}i)}
                        \PY{c+c1}{\PYZsh{}}
                        \PY{c+c1}{\PYZsh{} \PYZsh{} 为将卷积后张量各个分量合并为向量做准备}
                        \PY{c+c1}{\PYZsh{} assert capsules[0].get\PYZus{}shape() == [batch\PYZus{}size, 1152, 1, 1]}
                        \PY{c+c1}{\PYZsh{}}
                        \PY{c+c1}{\PYZsh{} \PYZsh{} 合并为PrimaryCaps的输出张量，即6×6×32个长度为8的向量，合并后的维度为 [batch\PYZus{}size, 1152, 8, 1]}
                        \PY{c+c1}{\PYZsh{} capsules = tf.concat(capsules, axis=2)}
                        \PY{c+c1}{\PYZsh{} \PYZsh{} 将每个Capsule 向量投入非线性函数squash进行缩放与激活,第二层输出的向量要经过缩放}
                        \PY{c+c1}{\PYZsh{} capsules = squash(capsules)}
                        \PY{c+c1}{\PYZsh{} assert capsules.get\PYZus{}shape() == [batch\PYZus{}size, 1152, 8, 1]}
                        \PY{c+c1}{\PYZsh{} return(capsules)}
        
                        \PY{c+c1}{\PYZsh{} 以下更新后的计算方法}
                        \PY{n}{capsules} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{num\PYZus{}outputs} \PY{o}{*} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{vec\PYZus{}len}\PY{p}{,}
                                                            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{kernel\PYZus{}size}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{stride}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VALID}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                        \PY{n}{capsules} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{capsules}\PY{p}{,} \PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{vec\PYZus{}len}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        
                        \PY{c+c1}{\PYZsh{} [batch\PYZus{}size, 1152, 8, 1]}
                        \PY{n}{capsules} \PY{o}{=} \PY{n}{squash}\PY{p}{(}\PY{n}{capsules}\PY{p}{)}
                        \PY{k}{assert} \PY{n}{capsules}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
                        \PY{k}{return} \PY{p}{(}\PY{n}{capsules}\PY{p}{)}
        
                \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}type} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FC}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        
                    \PY{c+c1}{\PYZsh{} DigitCaps 带有Routing过程}
                    \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{with\PYZus{}routing}\PY{p}{:}
                        \PY{c+c1}{\PYZsh{} CapsNet 的第三层 DigitCaps 层是一个全连接网络}
                        \PY{c+c1}{\PYZsh{} 将输入张量重建为 [batch\PYZus{}size, 1152, 1, 8, 1]}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{input}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{value}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        
                        \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{routing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                            \PY{c+c1}{\PYZsh{} 初始化b\PYZus{}IJ的值为零，且维度满足: [1, 1, num\PYZus{}caps\PYZus{}l, num\PYZus{}caps\PYZus{}l\PYZus{}plus\PYZus{}1, 1]}
                            \PY{n}{b\PYZus{}IJ} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{constant}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{input}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{value}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{num\PYZus{}outputs}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{)}\PY{p}{)}
                            \PY{c+c1}{\PYZsh{} 使用定义的Routing过程计算权值更新与s\PYZus{}j}
                            \PY{n}{capsules} \PY{o}{=} \PY{n}{routing}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input}\PY{p}{,} \PY{n}{b\PYZus{}IJ}\PY{p}{)}
                            \PY{c+c1}{\PYZsh{} 将s\PYZus{}j投入 squeeze 函数以得出 DigitCaps 层的输出向量}
                            \PY{n}{capsules} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{n}{capsules}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
                    \PY{k}{return}\PY{p}{(}\PY{n}{capsules}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} 定义路由算法的过程}
        \PY{k}{def} \PY{n+nf}{routing}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{n}{b\PYZus{}IJ}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{} 路由算法}
        
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        input: 输入张量的维度为 [batch\PYZus{}size, num\PYZus{}caps\PYZus{}l=1152, 1, length(u\PYZus{}i)=8, 1]}
        \PY{l+s+sd}{               其中num\PYZus{}caps\PYZus{}l为上一层（PrimaryCaps）的Capsule单元数量}
        \PY{l+s+sd}{    Returns:}
        \PY{l+s+sd}{        返回的张量维度为 [batch\PYZus{}size, num\PYZus{}caps\PYZus{}l\PYZus{}plus\PYZus{}1, length(v\PYZus{}j)=16, 1]}
        \PY{l+s+sd}{        表征了i+1层的输出向量 `v\PYZus{}j`，num\PYZus{}caps\PYZus{}l\PYZus{}plus\PYZus{}1 为DigitCaps层的输出数}
        \PY{l+s+sd}{    Notes:}
        \PY{l+s+sd}{        u\PYZus{}i 表示l层中 capsule i 的输出向量}
        \PY{l+s+sd}{        v\PYZus{}j 表示l+1层中 capsule j 的输出向量}
        \PY{l+s+sd}{     \PYZsq{}\PYZsq{}\PYZsq{}}
        
            \PY{c+c1}{\PYZsh{} 定义W的张量维度为 [num\PYZus{}caps\PYZus{}j, num\PYZus{}caps\PYZus{}i, len\PYZus{}u\PYZus{}i, len\PYZus{}v\PYZus{}j]}
            \PY{c+c1}{\PYZsh{} W\PYZus{}ij共有1152×10个，每一个的维度为8×16}
            \PY{n}{W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}variable}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,}
                                \PY{n}{initializer}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{random\PYZus{}normal\PYZus{}initializer}\PY{p}{(}\PY{n}{stddev}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} 论文中的 Eq.2, 计算 u\PYZus{}hat}
            \PY{c+c1}{\PYZsh{} 在使用 W 和u\PYZus{}i计算u\PYZus{}hat前，先调整张量维度}
            \PY{c+c1}{\PYZsh{} input =\PYZgt{} [batch\PYZus{}size, 1152, 10, 8, 1]}
            \PY{c+c1}{\PYZsh{} W =\PYZgt{} [batch\PYZus{}size, 1152, 10, 8, 16]}
            \PY{n+nb}{input} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tile}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
            \PY{n}{W} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tile}\PY{p}{(}\PY{n}{W}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
            \PY{k}{assert} \PY{n+nb}{input}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
            \PY{c+c1}{\PYZsh{} 因为[8, 16].T x [8, 1] =\PYZgt{} [16, 1]，所以矩阵乘法在最后得出的维度为 [batch\PYZus{}size, 1152, 10, 16, 1]}
            \PY{n}{u\PYZus{}hat} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{W}\PY{p}{,} \PY{n+nb}{input}\PY{p}{,} \PY{n}{transpose\PYZus{}a}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
            \PY{k}{assert} \PY{n}{u\PYZus{}hat}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
            \PY{c+c1}{\PYZsh{} 前面是扩展的线性组合，后面是路由的部分，以下开始迭代路由过程更新耦合系数}
            \PY{c+c1}{\PYZsh{} 对应论文中伪代码的第三行}
            \PY{k}{for} \PY{n}{r\PYZus{}iter} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{iter\PYZus{}routing}\PY{p}{)}\PY{p}{:}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{iter\PYZus{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{r\PYZus{}iter}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} 原论文伪代码第四行，计算softmax(b\PYZus{}ij)}
                    \PY{c+c1}{\PYZsh{} =\PYZgt{} [1, 1152, 10, 1,1]}
                    \PY{n}{c\PYZus{}IJ} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{b\PYZus{}IJ}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
                    \PY{n}{c\PYZus{}IJ} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tile}\PY{p}{(}\PY{n}{c\PYZus{}IJ}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{c\PYZus{}IJ}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
                    \PY{c+c1}{\PYZsh{} 原论文伪代码第五行，根据更新的c\PYZus{}ij计算s\PYZus{}j}
                    \PY{c+c1}{\PYZsh{} 先利用 c\PYZus{}IJ 给 u\PYZus{}hat 加权，即在后两个维度采用对应元素的乘积}
                    \PY{c+c1}{\PYZsh{} =\PYZgt{} [batch\PYZus{}size, 1152, 10, 16, 1]}
                    \PY{n}{s\PYZus{}J} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{c\PYZus{}IJ}\PY{p}{,} \PY{n}{u\PYZus{}hat}\PY{p}{)}
                    \PY{c+c1}{\PYZsh{} 在第二个维度上求和, 产生的张量维度为 [batch\PYZus{}size, 1, 10, 16, 1]}
                    \PY{n}{s\PYZus{}J} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{s\PYZus{}J}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{s\PYZus{}J}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
                    \PY{c+c1}{\PYZsh{} 原论文伪代码的第六行}
                    \PY{c+c1}{\PYZsh{} 使用 Eq.1 计算squashing非线性函数}
                    \PY{n}{v\PYZus{}J} \PY{o}{=} \PY{n}{squash}\PY{p}{(}\PY{n}{s\PYZus{}J}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{v\PYZus{}J}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
                    \PY{c+c1}{\PYZsh{} 原论文伪代码的第七行}
                    \PY{c+c1}{\PYZsh{} reshape \PYZam{} tile v\PYZus{}j from [batch\PYZus{}size ,1, 10, 16, 1] to [batch\PYZus{}size, 10, 1152, 16, 1]}
                    \PY{c+c1}{\PYZsh{} then matmul in the last tow dim: [16, 1].T x [16, 1] =\PYZgt{} [1, 1], reduce mean in the}
                    \PY{c+c1}{\PYZsh{} batch\PYZus{}size dim, resulting in [1, 1152, 10, 1, 1]}
                    \PY{n}{v\PYZus{}J\PYZus{}tiled} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tile}\PY{p}{(}\PY{n}{v\PYZus{}J}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
                    \PY{n}{u\PYZus{}produce\PYZus{}v} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{u\PYZus{}hat}\PY{p}{,} \PY{n}{v\PYZus{}J\PYZus{}tiled}\PY{p}{,} \PY{n}{transpose\PYZus{}a}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{u\PYZus{}produce\PYZus{}v}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
                    \PY{n}{b\PYZus{}IJ} \PY{o}{+}\PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{u\PYZus{}produce\PYZus{}v}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        
            \PY{k}{return}\PY{p}{(}\PY{n}{v\PYZus{}J}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k}{def} \PY{n+nf}{squash}\PY{p}{(}\PY{n}{vector}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{} 根据原论文中 Eq. 1 定义squashing函数}
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        vector: 一个 5\PYZhy{}D 张量，其维度是 [batch\PYZus{}size, 1, num\PYZus{}caps, vec\PYZus{}len, 1],}
        \PY{l+s+sd}{    Returns:}
        \PY{l+s+sd}{        返回一个 5\PYZhy{}D 张量，其第四和第五个维度经过了该非线性函数据算}
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{vec\PYZus{}squared\PYZus{}norm} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{vector}\PY{p}{)}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
            \PY{n}{scalar\PYZus{}factor} \PY{o}{=} \PY{n}{vec\PYZus{}squared\PYZus{}norm} \PY{o}{/} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{n}{vec\PYZus{}squared\PYZus{}norm}\PY{p}{)} \PY{o}{/} \PY{n}{tf}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{vec\PYZus{}squared\PYZus{}norm} \PY{o}{+} \PY{n}{epsilon}\PY{p}{)}
            \PY{n}{vec\PYZus{}squashed} \PY{o}{=} \PY{n}{scalar\PYZus{}factor} \PY{o}{*} \PY{n}{vector}  \PY{c+c1}{\PYZsh{} element\PYZhy{}wise}
            \PY{k}{return}\PY{p}{(}\PY{n}{vec\PYZus{}squashed}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} 以下定义整个 CapsNet 的架构与正向传播过程}
        \PY{k}{class} \PY{n+nc}{CapsNet}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{is\PYZus{}training}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}
                \PY{k}{with} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph}\PY{o}{.}\PY{n}{as\PYZus{}default}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                    \PY{k}{if} \PY{n}{is\PYZus{}training}\PY{p}{:}
                        \PY{c+c1}{\PYZsh{} 获取一个批量的训练数据}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{X}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{Y} \PY{o}{=} \PY{n}{get\PYZus{}batch\PYZus{}data}\PY{p}{(}\PY{p}{)}
        
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{build\PYZus{}arch}\PY{p}{(}\PY{p}{)}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss}\PY{p}{(}\PY{p}{)}
        
                        \PY{c+c1}{\PYZsh{} t\PYZus{}vars = tf.trainable\PYZus{}variables()}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{optimizer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{p}{)}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{global\PYZus{}step} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{global\PYZus{}step}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{trainable}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{train\PYZus{}op} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{optimizer}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{total\PYZus{}loss}\PY{p}{,} \PY{n}{global\PYZus{}step}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{global\PYZus{}step}\PY{p}{)}  \PY{c+c1}{\PYZsh{} var\PYZus{}list=t\PYZus{}vars)}
                    \PY{k}{else}\PY{p}{:}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{X} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,}
                                                \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{build\PYZus{}arch}\PY{p}{(}\PY{p}{)}
        
                \PY{n}{tf}\PY{o}{.}\PY{n}{logging}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Seting up the main structure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} CapsNet 类中的build\PYZus{}arch方法能构建整个网络的架构}
            \PY{k}{def} \PY{n+nf}{build\PYZus{}arch}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} 以下构建第一个常规卷积层}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Conv1\PYZus{}layer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} 第一个卷积层的输出张量为： [batch\PYZus{}size, 20, 20, 256]}
                    \PY{c+c1}{\PYZsh{} 以下卷积输入图像X,采用256个9×9的卷积核，步幅为1，且不使用}
                    \PY{n}{conv1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{X}\PY{p}{,} \PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{l+m+mi}{256}\PY{p}{,}
                                                     \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{9}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
                                                     \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VALID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    \PY{c+c1}{\PYZsh{} 是用 assert 可以在出现错误条件时就返回错误，有助于调整}
                    \PY{k}{assert} \PY{n}{conv1}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{]}
        
                \PY{c+c1}{\PYZsh{} 以下是原论文中PrimaryCaps层的构建过程，该层的输出维度为 [batch\PYZus{}size, 1152, 8, 1]}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PrimaryCaps\PYZus{}layer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} 调用前面定义的CapLayer函数构建第二个卷积层，该过程相当于执行八次常规卷积，}
                    \PY{c+c1}{\PYZsh{} 然后将各对应位置的元素组合成一个长度为8的向量，这八次常规卷积都是采用32个9×9的卷积核、步幅为2}
                    \PY{n}{primaryCaps} \PY{o}{=} \PY{n}{CapsLayer}\PY{p}{(}\PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{vec\PYZus{}len}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{with\PYZus{}routing}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{layer\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CONV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    \PY{n}{caps1} \PY{o}{=} \PY{n}{primaryCaps}\PY{p}{(}\PY{n}{conv1}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{9}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{caps1}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1152}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
                \PY{c+c1}{\PYZsh{} 以下构建 DigitCaps 层, 该层返回的张量维度为 [batch\PYZus{}size, 10, 16, 1]}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DigitCaps\PYZus{}layer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} DigitCaps是最后一层，它返回对应10个类别的向量（每个有16个元素），该层的构建带有Routing过程}
                    \PY{n}{digitCaps} \PY{o}{=} \PY{n}{CapsLayer}\PY{p}{(}\PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{vec\PYZus{}len}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,} \PY{n}{with\PYZus{}routing}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{layer\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FC}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{caps2} \PY{o}{=} \PY{n}{digitCaps}\PY{p}{(}\PY{n}{caps1}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} 以下构建论文图2中的解码结构，即由16维向量重构出对应类别的整个图像}
                \PY{c+c1}{\PYZsh{} 1. Do masking, how:}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Masking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} Method 1. masking with true label, default mode}
        
                    \PY{c+c1}{\PYZsh{} mask\PYZus{}with\PYZus{}y是否用真实标签蒙住目标Capsule}
                    \PY{n}{mask\PYZus{}with\PYZus{}y}\PY{o}{=}\PY{n+nb+bp}{True}
                    \PY{k}{if} \PY{n}{mask\PYZus{}with\PYZus{}y}\PY{p}{:}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{masked\PYZus{}v} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{caps2}\PY{p}{)}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{Y}\PY{p}{,} \PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{transpose\PYZus{}a}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
                        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{v\PYZus{}length} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{caps2}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)} \PY{o}{+} \PY{n}{epsilon}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} 通过3个全连接层重构MNIST图像，这三个全连接层的神经元数分别为512、1024、784}
                \PY{c+c1}{\PYZsh{} [batch\PYZus{}size, 1, 16, 1] =\PYZgt{} [batch\PYZus{}size, 16] =\PYZgt{} [batch\PYZus{}size, 512]}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Decoder}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{n}{vector\PYZus{}j} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{masked\PYZus{}v}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                    \PY{n}{fc1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n}{vector\PYZus{}j}\PY{p}{,} \PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{l+m+mi}{512}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{fc1}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{512}\PY{p}{]}
                    \PY{n}{fc2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n}{fc1}\PY{p}{,} \PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{l+m+mi}{1024}\PY{p}{)}
                    \PY{k}{assert} \PY{n}{fc2}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1024}\PY{p}{]}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{decoded} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n}{fc2}\PY{p}{,} \PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{l+m+mi}{784}\PY{p}{,} \PY{n}{activation\PYZus{}fn}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{sigmoid}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} 定义 CapsNet 的损失函数，损失函数一共分为衡量 CapsNet准确度的Margin loss}
            \PY{c+c1}{\PYZsh{} 和衡量重构图像准确度的 Reconstruction loss}
            \PY{k}{def} \PY{n+nf}{loss}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} 以下先定义重构损失，因为DigitCaps的输出向量长度就为某类别的概率，因此可以借助计算向量长度计算损失}
                \PY{c+c1}{\PYZsh{} [batch\PYZus{}size, 10, 1, 1]}
                \PY{c+c1}{\PYZsh{} max\PYZus{}l = max(0, m\PYZus{}plus\PYZhy{}||v\PYZus{}c||)\PYZca{}2}
                \PY{n}{max\PYZus{}l} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{maximum}\PY{p}{(}\PY{l+m+mf}{0.}\PY{p}{,} \PY{n}{m\PYZus{}plus} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{v\PYZus{}length}\PY{p}{)}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} max\PYZus{}r = max(0, ||v\PYZus{}c||\PYZhy{}m\PYZus{}minus)\PYZca{}2}
                \PY{n}{max\PYZus{}r} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{maximum}\PY{p}{(}\PY{l+m+mf}{0.}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{v\PYZus{}length} \PY{o}{\PYZhy{}} \PY{n}{m\PYZus{}minus}\PY{p}{)}\PY{p}{)}
                \PY{k}{assert} \PY{n}{max\PYZus{}l}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        
                \PY{c+c1}{\PYZsh{} 将当前的维度[batch\PYZus{}size, 10, 1, 1] 转换为10个数字类别的one\PYZhy{}hot编码 [batch\PYZus{}size, 10]}
                \PY{n}{max\PYZus{}l} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{max\PYZus{}l}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                \PY{n}{max\PYZus{}r} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{max\PYZus{}r}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} 计算 T\PYZus{}c: [batch\PYZus{}size, 10]，其为分类的指示函数}
                \PY{c+c1}{\PYZsh{} 若令T\PYZus{}c = Y,那么对应元素相乘就是有类别相同才会有非零输出值，T\PYZus{}c 和 Y 都为One\PYZhy{}hot编码}
                \PY{n}{T\PYZus{}c} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{Y}
                \PY{c+c1}{\PYZsh{} [batch\PYZus{}size, 10], 对应元素相乘并构建最后的Margin loss 函数}
                \PY{n}{L\PYZus{}c} \PY{o}{=} \PY{n}{T\PYZus{}c} \PY{o}{*} \PY{n}{max\PYZus{}l} \PY{o}{+} \PY{n}{lambda\PYZus{}val} \PY{o}{*} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{T\PYZus{}c}\PY{p}{)} \PY{o}{*} \PY{n}{max\PYZus{}r}
        
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{margin\PYZus{}loss} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{L\PYZus{}c}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} 以下构建reconstruction loss函数}
                \PY{c+c1}{\PYZsh{} 这一过程的损失函数通过计算FC Sigmoid层的输出像素点与原始图像像素点间的欧几里德距离而构建}
                \PY{n}{orgin} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{X}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                \PY{n}{squared} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{decoded} \PY{o}{\PYZhy{}} \PY{n}{orgin}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{reconstruction\PYZus{}err} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{squared}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} 构建总损失函数，Hinton论文将reconstruction loss乘上0.0005}
                \PY{c+c1}{\PYZsh{} 以使它不会主导训练过程中的Margin loss}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{total\PYZus{}loss} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{margin\PYZus{}loss} \PY{o}{+} \PY{l+m+mf}{0.0005} \PY{o}{*} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{reconstruction\PYZus{}err}
        
                \PY{c+c1}{\PYZsh{} 以下输出TensorBoard}
                \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{scalar}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{margin\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{margin\PYZus{}loss}\PY{p}{)}
                \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{scalar}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reconstruction\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{reconstruction\PYZus{}err}\PY{p}{)}
                \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{scalar}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{total\PYZus{}loss}\PY{p}{)}
                \PY{n}{recon\PYZus{}img} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{decoded}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{image}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reconstruction\PYZus{}img}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{recon\PYZus{}img}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{merged\PYZus{}sum} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{merge\PYZus{}all}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} 训练和推断}
            \PY{n}{capsNet} \PY{o}{=} \PY{n}{CapsNet}\PY{p}{(}\PY{n}{is\PYZus{}training}\PY{o}{=}\PY{n}{is\PYZus{}training}\PY{p}{)}
            \PY{n}{tf}\PY{o}{.}\PY{n}{logging}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Graph loaded}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{sv} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{Supervisor}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{capsNet}\PY{o}{.}\PY{n}{graph}\PY{p}{,}
                                     \PY{n}{logdir}\PY{o}{=}\PY{n}{logdir}\PY{p}{,}
                                     \PY{n}{save\PYZus{}model\PYZus{}secs}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        
            \PY{k}{with} \PY{n}{sv}\PY{o}{.}\PY{n}{managed\PYZus{}session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
                \PY{n}{num\PYZus{}batch} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{l+m+mi}{60000} \PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)}
                \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{epoch}\PY{p}{)}\PY{p}{:}
                    \PY{k}{if} \PY{n}{sv}\PY{o}{.}\PY{n}{should\PYZus{}stop}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                        \PY{k}{break}
                    \PY{k}{for} \PY{n}{step} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}batch}\PY{p}{)}\PY{p}{,} \PY{n}{total}\PY{o}{=}\PY{n}{num\PYZus{}batch}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{70}\PY{p}{,} \PY{n}{leave}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{unit}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                        \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{capsNet}\PY{o}{.}\PY{n}{train\PYZus{}op}\PY{p}{)}
        
                    \PY{n}{global\PYZus{}step} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{capsNet}\PY{o}{.}\PY{n}{global\PYZus{}step}\PY{p}{)}
                    \PY{n}{sv}\PY{o}{.}\PY{n}{saver}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{logdir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/model\PYZus{}epoch\PYZus{}}\PY{l+s+si}{\PYZpc{}04d}\PY{l+s+s1}{\PYZus{}step\PYZus{}}\PY{l+s+si}{\PYZpc{}02d}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{epoch}\PY{p}{,} \PY{n}{global\PYZus{}step}\PY{p}{)}\PY{p}{)}
        
            \PY{n}{tf}\PY{o}{.}\PY{n}{logging}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training done}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Seting up the main structure
INFO:tensorflow:Graph loaded
INFO:tensorflow:Starting standard services.
INFO:tensorflow:Starting queue runners.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  0\%|                                         | 0/7500 [00:00<?, ?b/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0
INFO:tensorflow:Recording summary at step 0.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  1\%|▏                             | 62/7500 [01:59<3:59:18,  1.93s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.516211
INFO:tensorflow:Recording summary at step 62.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  2\%|▍                            | 127/7500 [03:58<3:50:49,  1.88s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.541764

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  2\%|▍                            | 128/7500 [04:00<3:51:15,  1.88s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 128.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  3\%|▋                            | 193/7500 [05:58<3:46:20,  1.86s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.549639

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  3\%|▊                            | 194/7500 [06:01<3:46:35,  1.86s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 194.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  3\%|█                            | 259/7500 [07:58<3:42:56,  1.85s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.550047

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  3\%|█                            | 260/7500 [08:00<3:43:03,  1.85s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 260.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  4\%|█▎                           | 325/7500 [09:59<3:40:24,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.550611
INFO:tensorflow:Recording summary at step 325.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  5\%|█▌                           | 391/7500 [11:59<3:37:55,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.549691
INFO:tensorflow:Recording summary at step 391.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  6\%|█▊                           | 456/7500 [13:58<3:35:54,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.541295

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  6\%|█▊                           | 457/7500 [14:01<3:36:02,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 457.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  7\%|██                           | 522/7500 [15:59<3:33:45,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.550592
INFO:tensorflow:Recording summary at step 522.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  8\%|██▎                          | 588/7500 [17:59<3:31:34,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:global\_step/sec: 0.549879
INFO:tensorflow:Recording summary at step 588.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
  9\%|██▌                          | 654/7500 [20:00<3:29:29,  1.84s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 654.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 10\%|██▊                          | 719/7500 [21:59<3:27:20,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 719.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 10\%|███                          | 785/7500 [23:59<3:25:12,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 785.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 11\%|███▎                         | 851/7500 [25:59<3:23:05,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 851.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 12\%|███▌                         | 916/7500 [27:59<3:21:12,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 916.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 13\%|███▊                         | 982/7500 [29:59<3:19:05,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 982.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 14\%|███▉                        | 1048/7500 [31:59<3:16:59,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1048.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 15\%|████▏                       | 1114/7500 [34:01<3:15:00,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1114.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 16\%|████▍                       | 1180/7500 [36:01<3:12:56,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1180.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 17\%|████▋                       | 1245/7500 [37:59<3:10:50,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1245.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 17\%|████▉                       | 1311/7500 [39:59<3:08:45,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1311.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 18\%|█████▏                      | 1377/7500 [41:59<3:06:42,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1377.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 19\%|█████▍                      | 1443/7500 [43:59<3:04:38,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1443.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 20\%|█████▋                      | 1509/7500 [45:59<3:02:36,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1509.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 21\%|█████▉                      | 1574/7500 [48:00<3:00:44,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1574.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 22\%|██████                      | 1639/7500 [49:59<2:58:46,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1639.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 23\%|██████▎                     | 1705/7500 [52:00<2:56:44,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1705.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 24\%|██████▌                     | 1771/7500 [54:00<2:54:43,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1771.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 24\%|██████▊                     | 1836/7500 [55:59<2:52:42,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1836.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 25\%|███████                     | 1902/7500 [57:59<2:50:40,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1902.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 26\%|███████▎                    | 1968/7500 [59:59<2:48:38,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 1968.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 27\%|███████                   | 2034/7500 [1:01:59<2:46:36,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2034.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 28\%|███████▎                  | 2100/7500 [1:04:00<2:44:36,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2100.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 29\%|███████▌                  | 2165/7500 [1:05:59<2:42:37,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2165.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 30\%|███████▋                  | 2231/7500 [1:07:59<2:40:35,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2231.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 31\%|███████▉                  | 2297/7500 [1:09:59<2:38:33,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2297.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 32\%|████████▏                 | 2363/7500 [1:12:00<2:36:32,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2363.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 32\%|████████▍                 | 2429/7500 [1:14:00<2:34:30,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2429.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 33\%|████████▋                 | 2495/7500 [1:16:00<2:32:29,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2495.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 34\%|████████▉                 | 2561/7500 [1:18:00<2:30:27,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2561.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 35\%|█████████                 | 2626/7500 [1:19:59<2:28:27,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2626.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 36\%|█████████▎                | 2692/7500 [1:21:59<2:26:26,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2692.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 37\%|█████████▌                | 2758/7500 [1:23:59<2:24:24,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2758.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 38\%|█████████▊                | 2824/7500 [1:25:59<2:22:23,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2824.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 39\%|██████████                | 2890/7500 [1:28:00<2:20:22,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2890.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 39\%|██████████▏               | 2956/7500 [1:30:00<2:18:22,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 2956.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 40\%|██████████▍               | 3022/7500 [1:32:01<2:16:21,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3022.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 41\%|██████████▋               | 3087/7500 [1:33:59<2:14:21,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3087.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 42\%|██████████▉               | 3153/7500 [1:35:59<2:12:20,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3153.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 43\%|███████████▏              | 3219/7500 [1:37:59<2:10:19,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3219.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 44\%|███████████▍              | 3285/7500 [1:40:00<2:08:18,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3285.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 45\%|███████████▌              | 3351/7500 [1:42:00<2:06:18,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3351.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 46\%|███████████▊              | 3417/7500 [1:44:00<2:04:17,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3417.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 46\%|████████████              | 3482/7500 [1:45:58<2:02:17,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3482.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 47\%|████████████▎             | 3548/7500 [1:47:59<2:00:17,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3548.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 48\%|████████████▌             | 3614/7500 [1:49:59<1:58:16,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3614.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 49\%|████████████▊             | 3679/7500 [1:52:00<1:56:20,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3679.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 50\%|████████████▉             | 3744/7500 [1:53:59<1:54:21,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3744.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 51\%|█████████████▏            | 3810/7500 [1:56:00<1:52:21,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3810.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 52\%|█████████████▍            | 3875/7500 [1:57:59<1:50:22,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3875.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 53\%|█████████████▋            | 3941/7500 [1:59:59<1:48:21,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 3941.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 53\%|█████████████▉            | 4007/7500 [2:02:00<1:46:21,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4007.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 54\%|██████████████            | 4073/7500 [2:03:59<1:44:19,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4073.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 55\%|██████████████▎           | 4139/7500 [2:06:00<1:42:19,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4139.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 56\%|██████████████▌           | 4205/7500 [2:08:00<1:40:18,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4205.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 57\%|██████████████▊           | 4269/7500 [2:09:59<1:38:22,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4269.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 58\%|███████████████           | 4333/7500 [2:11:59<1:36:28,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4333.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 59\%|███████████████▏          | 4396/7500 [2:14:00<1:34:37,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4396.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 59\%|███████████████▍          | 4460/7500 [2:16:01<1:32:42,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4460.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 60\%|███████████████▋          | 4525/7500 [2:18:00<1:30:44,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4525.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 61\%|███████████████▉          | 4590/7500 [2:20:01<1:28:46,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4590.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 62\%|████████████████▏         | 4655/7500 [2:21:59<1:26:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4655.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 63\%|████████████████▎         | 4720/7500 [2:23:58<1:24:48,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4720.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 64\%|████████████████▌         | 4786/7500 [2:25:59<1:22:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4786.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 65\%|████████████████▊         | 4852/7500 [2:28:00<1:20:46,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4852.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 66\%|█████████████████         | 4917/7500 [2:29:59<1:18:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4917.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 66\%|█████████████████▎        | 4983/7500 [2:32:00<1:16:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 4983.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 67\%|█████████████████▍        | 5048/7500 [2:33:59<1:14:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5048.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 68\%|█████████████████▋        | 5114/7500 [2:36:01<1:12:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5114.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 69\%|█████████████████▉        | 5179/7500 [2:37:59<1:10:48,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5179.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 70\%|██████████████████▏       | 5245/7500 [2:40:00<1:08:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5245.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 71\%|██████████████████▍       | 5310/7500 [2:41:59<1:06:48,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5310.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 72\%|██████████████████▋       | 5376/7500 [2:43:59<1:04:47,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5376.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 73\%|██████████████████▊       | 5441/7500 [2:45:59<1:02:49,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5441.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 73\%|███████████████████       | 5506/7500 [2:47:59<1:00:50,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5506.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 74\%|████████████████████▊       | 5571/7500 [2:49:59<58:51,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5571.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 75\%|█████████████████████       | 5637/7500 [2:52:00<56:50,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5637.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 76\%|█████████████████████▎      | 5702/7500 [2:54:00<54:52,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5702.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 77\%|█████████████████████▌      | 5767/7500 [2:55:59<52:53,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5767.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 78\%|█████████████████████▊      | 5831/7500 [2:57:59<50:56,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5831.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 79\%|██████████████████████      | 5896/7500 [2:59:59<48:58,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5896.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 79\%|██████████████████████▎     | 5962/7500 [3:02:00<46:57,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 5962.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 80\%|██████████████████████▌     | 6027/7500 [3:03:59<44:57,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6027.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 81\%|██████████████████████▋     | 6093/7500 [3:05:59<42:57,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6093.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 82\%|██████████████████████▉     | 6159/7500 [3:08:00<40:56,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6159.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 83\%|███████████████████████▏    | 6224/7500 [3:09:59<38:56,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6224.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 84\%|███████████████████████▍    | 6290/7500 [3:12:00<36:56,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6290.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 85\%|███████████████████████▋    | 6356/7500 [3:14:01<34:55,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6356.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 86\%|███████████████████████▉    | 6421/7500 [3:15:59<32:56,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6421.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 86\%|████████████████████████▏   | 6487/7500 [3:17:59<30:55,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6487.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 87\%|████████████████████████▍   | 6553/7500 [3:20:00<28:54,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6553.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 88\%|████████████████████████▋   | 6618/7500 [3:21:59<26:55,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6618.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 89\%|████████████████████████▉   | 6684/7500 [3:23:59<24:54,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6684.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 90\%|█████████████████████████▏  | 6750/7500 [3:26:00<22:53,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6750.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 91\%|█████████████████████████▍  | 6815/7500 [3:27:59<20:54,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6815.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 92\%|█████████████████████████▋  | 6881/7500 [3:29:59<18:53,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6881.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 93\%|█████████████████████████▉  | 6947/7500 [3:32:00<16:52,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 6947.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 93\%|██████████████████████████▏ | 7012/7500 [3:33:59<14:53,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7012.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 94\%|██████████████████████████▍ | 7078/7500 [3:35:59<12:52,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7078.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 95\%|██████████████████████████▋ | 7144/7500 [3:37:59<10:51,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7144.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 96\%|██████████████████████████▉ | 7210/7500 [3:40:00<08:50,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7210.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 97\%|███████████████████████████▏| 7276/7500 [3:42:01<06:50,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7276.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 98\%|███████████████████████████▍| 7341/7500 [3:43:59<04:51,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7341.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
 99\%|███████████████████████████▋| 7407/7500 [3:45:59<02:50,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7407.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|███████████████████████████▉| 7473/7500 [3:47:59<00:49,  1.83s/b]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Recording summary at step 7473.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
                                                                      
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Training done

    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
